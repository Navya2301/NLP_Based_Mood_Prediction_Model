{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOVVqkrSXjYoSzuLVG687zO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Navya2301/NLP_Based_Mood_Prediction_Model/blob/main/MoodDetection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#NLP-based mood prediction model\n",
        "\n",
        "Project overview : I would like to design a model that predicts the mood based on user-written notes and responds with supportive messages.\n",
        "Key Concepts: Sentiment Analysis, Text Classification, NLP Pipelines.\n",
        "\n",
        "####Key Concepts:\n",
        "Sentiment Analysis, Text Classification, NLP Pipelines.\n",
        "\n",
        "####Tools and Libraries:\n",
        "\n",
        "1.   Python: The primary language for this project..\n",
        "2. NLP Libraries: NLTK, SpaCy, and Hugging Face Transformers.\n",
        "3. Machine Learning Libraries: Scikit-learn, TensorFlow, or PyTorch.\n"
      ],
      "metadata": {
        "id": "2jkmEJ5vz9Zq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data set I have used is Emotion Dataset from Hugging face ðŸ¤— - https://huggingface.co/datasets/dair-ai/emotion"
      ],
      "metadata": {
        "id": "EOyi20Ho-EPt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary libraries using pip\n",
        "\n",
        "!pip install nltk spacy transformers scikit-learn\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "SxbKqZ0F0wh0",
        "outputId": "c61be624-1c70-4bff-b9c3-ddbd94b05ee3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.6)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.42.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.3.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.12.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.8.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (71.0.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.26.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.5)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.4)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.20.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.7.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.8.0)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.18.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.16.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.16.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "zZZVg5MyGWyx"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Collection\n",
        "\n",
        "# Concepts: Dataset Collection, Data Labeling.\n",
        "\n",
        "splits = {'train': 'split/train-00000-of-00001.parquet', 'validation': 'split/validation-00000-of-00001.parquet', 'test': 'split/test-00000-of-00001.parquet'}\n",
        "df = pd.read_parquet(\"hf://datasets/dair-ai/emotion/\" + splits[\"train\"])\n",
        "\n",
        "#ds = load_dataset(\"dair-ai/emotion\", \"split\")"
      ],
      "metadata": {
        "id": "25RuG0Ee-8I9"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.head())\n",
        "\n",
        "# 0 - sadness , 1 - joy , 2- love , 3 - anger, 4 - fear, 5 - surprise,"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nSwfbAS9HKtU",
        "outputId": "9248b930-acb5-4e27-92fa-754992ca954f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                text  label\n",
            "0                            i didnt feel humiliated      0\n",
            "1  i can go from feeling so hopeless to so damned...      0\n",
            "2   im grabbing a minute to post i feel greedy wrong      3\n",
            "3  i am ever feeling nostalgic about the fireplac...      2\n",
            "4                               i am feeling grouchy      3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data preprocessing\n",
        "\n",
        "# Concepts: Tokenization, Lemmatization, Stop Words Removal.\n",
        "\n",
        "# we do it using NLTK\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# the below commands to download the NLTK data to do necessary actions (Tokenization, Lemmatization, Stop Words Removal.)\n",
        "\n",
        "# Are these necessary ?\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vpmtl-qV_5s6",
        "outputId": "2edf1070-c045-4250-f99a-8c5276d6af16"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "When working with natural language processing tasks in NLTK, you need these resources to ensure that your text processing functions work correctly. Without them, the NLTK functions like tokenization, lemmatization, and stop words removal wouldnâ€™t have the necessary data to operate.\n",
        "\n",
        "**nltk.download('punkt')**  -- Downloads the Punkt tokenizer models, which are used for sentence and word tokenization.The word_tokenize function from NLTK relies on the Punkt tokenizer to split a sentence into individual words (tokens). Without downloading the Punkt tokenizer, the word_tokenize function wouldn't work because it requires these models to accurately identify the boundaries of words and sentences.\n",
        "\n",
        "**nltk.download('stopwords')** -- Downloads a list of common stop words (like \"the,\" \"and,\" \"is,\" etc.) for different languages.\n",
        "\n",
        "**nltk.download('wordnet')** -- Downloads the WordNet lexical database, which is a large database of English words, including their meanings, synonyms, antonyms, and more."
      ],
      "metadata": {
        "id": "F_edKbxGK3rg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# here we are initialising the lemmatizer and stopwords\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stop_words = set(stopwords.words('english'))"
      ],
      "metadata": {
        "id": "7YYgprAtK7bj"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can choose a different language for the stop words, and even for tokenization and lemmatization tasks if needed. NLTK supports multiple languages for these tasks, but the availability varies depending on the specific task.\n",
        "\n",
        "#### Stop Words:\n",
        " The stopwords.words('english') function requires a language argument because stop words differ from language to language. For instance, common English stop words like \"the\" or \"and\" do not apply to other languages, so you must specify the language youâ€™re working with.\n",
        "\n",
        " #### Tokenization:\n",
        " The word_tokenize function in NLTK is generally language-agnostic. It works reasonably well for many languages without requiring a language setting because it primarily splits text based on spaces and punctuation. However, for languages with different tokenization rules (like Chinese or Japanese), more specialized tokenizers might be needed.\n",
        "\n",
        " #### Lemmatization:\n",
        " The WordNetLemmatizer primarily supports English because it relies on the WordNet lexical database, which is English-specific. If youâ€™re working with another language, you would need a lemmatizer that supports that language, and NLTK might not have it by default.\n",
        "\n",
        "#### Will They Function Properly Without Language Setting?\n",
        "**Stop Words:** If you don't specify the language, the default in NLTK is typically English. However, if you don't specify the language when using stop words, you might run into issues if your text is in a different language.\n",
        "\n",
        "**Tokenization and Lemmatization:**\n",
        "These will still function without a language setting, but the effectiveness may vary. For tokenization, it usually works well for languages that use spaces to separate words. For lemmatization, without a proper lexical database for a specific language, it might not function correctly, as it is designed for English by default."
      ],
      "metadata": {
        "id": "cKQ029MbNv6s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# we should design a function that would take the data and do tokenization, lemmatization, and stop words removal\n",
        "\n",
        "def preprocess_text(text):\n",
        "    tokens = word_tokenize(text)\n",
        "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word.lower() not in stop_words]\n",
        "    return \" \".join(tokens)"
      ],
      "metadata": {
        "id": "2Npm5YeMNofL"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Feature Extraction\n",
        "**Goal:** Convert text into numerical features that a machine learning model can understand.\n",
        "\n",
        "**Concepts:** Bag of Words, TF-IDF, Word Embeddings.\n",
        "\n",
        "**Approach:**\n",
        "\n",
        "*Bag of Words (BoW):*  Simple model representing text as word frequency.\n",
        "\n",
        "*TF-IDF:*  Term Frequency-Inverse Document Frequency, considers the importance of words.\n",
        "\n",
        "*Word Embeddings:*  Use pre-trained models like Word2Vec or BERT for contextual understanding."
      ],
      "metadata": {
        "id": "DVcbqiO8P52f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For this project of predicting mood and responding with supportive notes, Word Embeddings (Word2Vec, GloVe) would be a strong starting point. They offer good balance between capturing semantic meaning and being computationally feasible. Further we can use, Contextualized Word Embeddings (BERT, GPT) which is ideal, especially if we need the model to understand the context in which words are used.\n",
        "\n",
        "\n",
        "When working on NLP tasks that involve word embeddings (such as Word2Vec), we need a library that can handle the computational aspects of these models. Gensim provides efficient implementations of these algorithms, making it easier to work with large text corpora and train models that produce word embeddings\n",
        "\n",
        "So using these genism open source library we can load and train models like Word2Vec etc or we can use pre-trained word vectors such as those from GloVe or Word2Vec. Pre-trained word vectors are word embeddings that have already been trained on a large corpus of text.When working on tasks that don't require highly domain-specific language, pre-trained vectors can offer a solid starting point.\n",
        "\n",
        "Genism provides a convenient way to load, manage, and apply these embeddings in your NLP projects. Gensim provides functions to load pre-trained word vectors into a KeyedVectors object. This object is optimized for storing and querying word vectors efficiently. You can load vectors trained in different formats, such as Word2Vec or GloVe, and immediately start using them in your project.\n"
      ],
      "metadata": {
        "id": "vayNSL8VcC4V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###4. Integrate into a Larger Pipeline\n",
        "In your mood detection project:\n",
        "\n",
        "Feature Extraction: Use the word vectors to represent user-written notes as dense vectors (e.g., by averaging word vectors).\n",
        "Model Training: Use these dense vectors as input features for training a machine learning model (like Logistic Regression, SVM, or a Neural Network) that predicts the mood.\n",
        "Generating Responses: Based on the predicted mood, you can generate supportive responses as needed."
      ],
      "metadata": {
        "id": "vZji9FtGtsKL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install gensim"
      ],
      "metadata": {
        "id": "Jn59hcAcLyJt"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To use Google's pre-trained Word2Vec model trained on the Google News dataset, you'll need to download it from an online source. The model is not included by default in any Python library, so you'll have to obtain it separately."
      ],
      "metadata": {
        "id": "oan2f0-W3p0x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "GaAMvqLj4pfO"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from gensim.models import KeyedVectors\n",
        "\n",
        "# model_path = '/content/drive/MyDrive/Colab Notebooks/GoogleNews-vectors-negative300.bin'\n",
        "# model = KeyedVectors.load_word2vec_format(model_path, binary=True)\n",
        "\n",
        "\n",
        "# def get_sentence_vector(sentence, model):\n",
        "#     # Average the vectors for all words in the sentence\n",
        "#     vectors = [model[word] for word in sentence if word in model]\n",
        "#     return np.mean(vectors, axis=0) if vectors else np.zeros(model.vector_size)\n",
        "\n",
        "# # Example: Apply to the entire dataset\n",
        "# sentence_vectors = [get_sentence_vector(sentence, word2vec_model.wv) for sentence in preprocessed_data]\n",
        "\n"
      ],
      "metadata": {
        "id": "fUh6V9OsPkk9"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# similarity = model.similarity('king', 'queen')\n",
        "# vector = model.most_similar('king', topn=5)\n",
        "# print(vector)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Aj6H_5K5JFaB"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['preprocessed_data'] = df['text'].apply(preprocess_text)"
      ],
      "metadata": {
        "id": "t2mH8aKdQ_Px"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "g7WgSWaFrCd6",
        "outputId": "d55b368e-7c2f-4e7a-e70a-53a238205a91"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  label  \\\n",
              "0                            i didnt feel humiliated      0   \n",
              "1  i can go from feeling so hopeless to so damned...      0   \n",
              "2   im grabbing a minute to post i feel greedy wrong      3   \n",
              "3  i am ever feeling nostalgic about the fireplac...      2   \n",
              "4                               i am feeling grouchy      3   \n",
              "\n",
              "                                   preprocessed_data  \n",
              "0                              didnt feel humiliated  \n",
              "1  go feeling hopeless damned hopeful around some...  \n",
              "2          im grabbing minute post feel greedy wrong  \n",
              "3  ever feeling nostalgic fireplace know still pr...  \n",
              "4                                    feeling grouchy  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-db6f3925-72a9-45dc-bc3d-df752769a495\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>preprocessed_data</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>i didnt feel humiliated</td>\n",
              "      <td>0</td>\n",
              "      <td>didnt feel humiliated</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>i can go from feeling so hopeless to so damned...</td>\n",
              "      <td>0</td>\n",
              "      <td>go feeling hopeless damned hopeful around some...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
              "      <td>3</td>\n",
              "      <td>im grabbing minute post feel greedy wrong</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
              "      <td>2</td>\n",
              "      <td>ever feeling nostalgic fireplace know still pr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>i am feeling grouchy</td>\n",
              "      <td>3</td>\n",
              "      <td>feeling grouchy</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-db6f3925-72a9-45dc-bc3d-df752769a495')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-db6f3925-72a9-45dc-bc3d-df752769a495 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-db6f3925-72a9-45dc-bc3d-df752769a495');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3256aa2a-5401-485f-8689-438c8bd2dad4\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3256aa2a-5401-485f-8689-438c8bd2dad4')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3256aa2a-5401-485f-8689-438c8bd2dad4 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 16000,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 15969,\n        \"samples\": [\n          \"i feel rather imbicilic or at least complacent\",\n          \"i was in the bathroom i had sat down to pee it was to make me feel submissive again per instructions\",\n          \"i am thrilled with the way my skin and hair feel if you are like me you are skeptical\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 5,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0,\n          3,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"preprocessed_data\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 15879,\n        \"samples\": [\n          \"didnt feel like missed one bit\",\n          \"feel blank loss hey old hat\",\n          \"throw ocean feel would missed something career win oscar\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import numpy as np\n",
        "# def get_sentence_vector(sentence, model):\n",
        "#     vectors = [model[word] for word in sentence if word in model]\n",
        "#     return np.mean(vectors, axis=0) if vectors else np.zeros(model.vector_size)\n",
        "     # converting all the words for a sentence into single vector\n",
        "\n",
        "\n",
        "# the above function applies model to the words that you sent as input which are also present in pre-trained vector model and returns the mean vector values of those words"
      ],
      "metadata": {
        "collapsed": true,
        "id": "4wtgHfB9RcfH"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# now converting the words into vectors and then sentences into a single vector to use the dataset for ML model\n",
        "# sentence_vectors = df['preprocessed_data'].apply(get_sentence_vector, model=model)"
      ],
      "metadata": {
        "id": "5aelzDjkZh9C"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sentence_vectors.head()"
      ],
      "metadata": {
        "id": "91GtJJPGrU6P"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Traditional NLP**: Feature extraction involves steps like vectorization using Word2Vec.\n",
        "**Transformers:** The model itself handles feature extraction by converting tokenized text into embeddings during the forward pass. The only feature extraction you need is minimal text preprocessing before tokenization.\n",
        "\n",
        "So which is why we won't be needing the above **sentence_vectors** as we don't use the vectorised data for transformer models"
      ],
      "metadata": {
        "id": "f3b4oT2oCd_f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###6. Building the Mood Prediction Model\n",
        "Goal: Train a model to predict the mood based on processed text.\n",
        "\n",
        "Concepts: Text Classification, Sentiment Analysis, Model Training.\n",
        "\n",
        "Approach: I'm using Transformer\n",
        "\n",
        "DistilRoBERTa-base is a smaller, faster, and lighter version of the RoBERTa model. It's part of the Distil* series of models, which are essentially distilled versions of larger transformer models. Distillation is a process where a smaller model (the student) is trained to replicate the behavior of a larger model (the teacher) with significantly fewer parameters, making it more efficient while retaining much of the original model's performance.\n",
        "\n",
        "Use Case: It's ideal if you want to balance performance and efficiency. You can use it for tasks like mood detection, sentiment analysis, or other text classification problems, especially if you need to deploy the model in a production environment with limited resources.\n"
      ],
      "metadata": {
        "id": "HAMrOZWlNY6n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# I would like to use Dispip install transformers\n",
        "!pip install transformers\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H01-8TgVpbF9",
        "outputId": "c5ff875c-90c7-4892-aa04-378eb5b5ae32"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.42.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.5)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.4)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.7.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from transformers import RobertaTokenizer, DistilBertModel\n",
        "\n",
        "# tokenizer = RobertaTokenizer.from_pretrained('distilroberta-base')\n",
        "# model = DistilBertModel.from_pretrained('distilroberta-base')\n"
      ],
      "metadata": {
        "id": "sBIjEP_hM00v"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def tokenize_sentences(sentences):\n",
        "#     tokens = tokenizer(sentences, padding=True, truncation=True, return_tensors='pt')\n",
        "#     return tokens\n",
        "\n",
        "# # Apply this to your preprocessed data\n",
        "# tokenized_data = df['preprocessed_data'].apply(tokenize_sentences)\n"
      ],
      "metadata": {
        "id": "wdjjDaKnfABi"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch\n",
        "# Import torch\n",
        "import torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vn1qn0FrHI2g",
        "outputId": "927e0599-191d-4db4-ef90-2d286cd14849"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def get_distilroberta_embeddings(tokenized_data):\n",
        "#     with torch.no_grad():\n",
        "#         outputs = model(**tokenized_data)\n",
        "#         # Get the last hidden state\n",
        "#         last_hidden_state = outputs.last_hidden_state\n",
        "#         # Take the mean of the embeddings (pooling strategy)\n",
        "#         sentence_embeddings = last_hidden_state.mean(dim=1)\n",
        "#         return sentence_embeddings\n",
        "\n",
        "\n",
        "# Result: sentence_embeddings is now a tensor of shape [batch_size, hidden_size]\n",
        "# , where each row is a fixed-size embedding vector representing an entire sentence.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Feature Extraction with Transformer"
      ],
      "metadata": {
        "id": "O1_HFJ5hFRN1"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#df['distilroberta_embeddings'] = tokenized_data.apply(get_distilroberta_embeddings)\n",
        "\n",
        "# this is only feaure extraction"
      ],
      "metadata": {
        "id": "7q0s5WmaHXBN"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "v59YiiXQeQQc",
        "outputId": "c4fca0c1-31ab-45d9-8581-c705a7a4d780"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  label  \\\n",
              "0                            i didnt feel humiliated      0   \n",
              "1  i can go from feeling so hopeless to so damned...      0   \n",
              "2   im grabbing a minute to post i feel greedy wrong      3   \n",
              "3  i am ever feeling nostalgic about the fireplac...      2   \n",
              "4                               i am feeling grouchy      3   \n",
              "\n",
              "                                   preprocessed_data  \n",
              "0                              didnt feel humiliated  \n",
              "1  go feeling hopeless damned hopeful around some...  \n",
              "2          im grabbing minute post feel greedy wrong  \n",
              "3  ever feeling nostalgic fireplace know still pr...  \n",
              "4                                    feeling grouchy  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-feaebd5f-5a75-4062-a2db-a023ca470bee\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>preprocessed_data</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>i didnt feel humiliated</td>\n",
              "      <td>0</td>\n",
              "      <td>didnt feel humiliated</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>i can go from feeling so hopeless to so damned...</td>\n",
              "      <td>0</td>\n",
              "      <td>go feeling hopeless damned hopeful around some...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
              "      <td>3</td>\n",
              "      <td>im grabbing minute post feel greedy wrong</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
              "      <td>2</td>\n",
              "      <td>ever feeling nostalgic fireplace know still pr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>i am feeling grouchy</td>\n",
              "      <td>3</td>\n",
              "      <td>feeling grouchy</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-feaebd5f-5a75-4062-a2db-a023ca470bee')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-feaebd5f-5a75-4062-a2db-a023ca470bee button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-feaebd5f-5a75-4062-a2db-a023ca470bee');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9613d7a3-9252-4398-b8da-849d1a93a134\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9613d7a3-9252-4398-b8da-849d1a93a134')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9613d7a3-9252-4398-b8da-849d1a93a134 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 16000,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 15969,\n        \"samples\": [\n          \"i feel rather imbicilic or at least complacent\",\n          \"i was in the bathroom i had sat down to pee it was to make me feel submissive again per instructions\",\n          \"i am thrilled with the way my skin and hair feel if you are like me you are skeptical\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 5,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0,\n          3,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"preprocessed_data\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 15879,\n        \"samples\": [\n          \"didnt feel like missed one bit\",\n          \"feel blank loss hey old hat\",\n          \"throw ocean feel would missed something career win oscar\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fine-tuning: You adjust the entire transformer modelâ€™s weights based on your labeled dataset. This is whatâ€™s typically referred to as \"model training\" in this context.\n",
        "\n",
        "\n",
        "\n",
        "Fine-Tuning DistilBERT for a Classification Task:\n",
        "Fine-tuning DistilBERT involves taking the pre-trained DistilBERT model and training it on your specific dataset for the classification tas\n",
        "\n"
      ],
      "metadata": {
        "id": "B2BedZoWvfZz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# actual model training\n",
        "!pip install transformers torch scikit-learn\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQl9d_FXt8K2",
        "outputId": "01bc224a-5858-4cc4-b465-57ecf4f97cde"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.42.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.0+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.3.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.5)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.4)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.7.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenizer: Converts raw text into a format suitable for the model.\n",
        "Model: DistilBertForSequenceClassification is a pre-trained DistilBERT model designed for classification tasks.\n",
        "Dataset and DataLoader: Organize and manage the data, allowing efficient batch processing during training.\n",
        "This setup prepares your data and model for fine-tuning, allowing you to train DistilBERT on your specific task."
      ],
      "metadata": {
        "id": "wru07F-yA83F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the tokenizer and model\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=6)  # num_labels=2 for binary classification\n",
        "\n",
        "# Tokenize your data\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, texts, labels):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        inputs = tokenizer(self.texts[idx], padding='max_length', truncation=True, return_tensors='pt', max_length=512)\n",
        "        inputs = {k: v.squeeze(0) for k, v in inputs.items()}\n",
        "        inputs['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "        return inputs\n",
        "\n",
        "# Split data into train and test sets\n",
        "train_texts, test_texts, train_labels, test_labels = train_test_split(df['preprocessed_data'], df['label'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Create datasets\n",
        "train_dataset = TextDataset(train_texts.tolist(), train_labels.tolist())\n",
        "test_dataset = TextDataset(test_texts.tolist(), test_labels.tolist())\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HX03o10g81FB",
        "outputId": "3ad369e8-b063-40b8-842a-fdb52065813e"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Fine tune the model\n",
        "\"Fine-Tune the Model\" section, which is crucial for adapting the pre-trained DistilBERT model to your specific classification task. This process involves training the model on your labeled dataset to optimize its performance on the task at hand.\n",
        "\n",
        "\n",
        "\n",
        "**Optimizer and Loss Function** are fundamental components in training any machine learning or deep learning model, not just transformer models. These components are essential for guiding the modelâ€™s learning process during training.\n",
        "\n"
      ],
      "metadata": {
        "id": "ybAd1fZ3BPDg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unique_labels = df['label'].unique()\n",
        "print(unique_labels)  # This will print out all unique labels in your dataset\n"
      ],
      "metadata": {
        "id": "FKjTLUCfYrbd",
        "outputId": "a913260c-adb0-4e31-ea29-7e6b5c30b2a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 3 2 5 4 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AdamW\n",
        "from torch.optim import AdamW\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Set up the optimizer and loss function\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "loss_fn = CrossEntropyLoss()\n",
        "\n",
        "# Move model to GPU if available\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "model.to(device)\n",
        "\n",
        "# Fine-tuning loop\n",
        "model.train()\n",
        "for epoch in range(3):  # Adjust the number of epochs as needed\n",
        "    for batch in tqdm(train_loader):\n",
        "        # Move batch to device\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(**batch)\n",
        "        loss = outputs.loss\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        print(f'Epoch {epoch+1}, Loss: {loss.item()}')\n"
      ],
      "metadata": {
        "id": "vYLx6piKBN8D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Evaluation\n",
        "model.eval()\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        # Move batch to device\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(**batch)\n",
        "        logits = outputs.logits\n",
        "        preds = torch.argmax(logits, dim=-1).cpu().numpy()\n",
        "\n",
        "        # Store predictions and labels\n",
        "        all_preds.extend(preds)\n",
        "        all_labels.extend(batch['labels'].cpu().numpy())\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(all_labels, all_preds)\n",
        "print(f'Test Accuracy: {accuracy}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "umhaPEr9fb4Z",
        "outputId": "095533ce-945b-4c25-833e-5be7076d0052"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.9315625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "print(classification_report(all_labels, all_preds))\n",
        "print(confusion_matrix(all_labels, all_preds))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OhnAYT15sRPI",
        "outputId": "e9e81cea-b620-4ac4-a891-2ad655a783e5"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.95      0.97       946\n",
            "           1       0.97      0.93      0.95      1021\n",
            "           2       0.81      0.96      0.88       296\n",
            "           3       0.92      0.94      0.93       427\n",
            "           4       0.91      0.86      0.88       397\n",
            "           5       0.71      0.99      0.83       113\n",
            "\n",
            "    accuracy                           0.93      3200\n",
            "   macro avg       0.89      0.94      0.91      3200\n",
            "weighted avg       0.94      0.93      0.93      3200\n",
            "\n",
            "[[895  10   0  22  19   0]\n",
            " [  1 946  69   0   0   5]\n",
            " [  0  10 285   0   0   1]\n",
            " [  2   6   0 403  14   2]\n",
            " [  4   4   0  11 340  38]\n",
            " [  0   1   0   0   0 112]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def test(new_text):\n",
        "  inputs = tokenizer(new_text, padding='max_length', truncation=True, return_tensors='pt', max_length=512)\n",
        "  inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "  model.to(device)\n",
        "  model.eval()  # Set the model to evaluation mode\n",
        "  with torch.no_grad():  # Disable gradient calculations\n",
        "      outputs = model(**inputs)\n",
        "      logits = outputs.logits\n",
        "      predicted_class = torch.argmax(logits, dim=-1).item()\n",
        "  emotion_mapping = {0: 'sadness', 1: 'joy', 2: 'love', 3: 'anger', 4: 'fear', 5: 'surprise'}\n",
        "  predicted_mood = emotion_mapping[predicted_class]\n",
        "  print(f'The predicted mood is: {predicted_mood}')\n"
      ],
      "metadata": {
        "id": "Ms-ESNnzoCjL"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test(\"I am doing fine\")\n",
        "\n",
        "# 0 - sadness , 1 - joy , 2- love , 3 - anger, 4 - fear, 5 - surprise,"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJDLps3voUTa",
        "outputId": "f0900354-4993-417b-e4ed-983684518f6e"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The predicted mood is: joy\n"
          ]
        }
      ]
    }
  ]
}